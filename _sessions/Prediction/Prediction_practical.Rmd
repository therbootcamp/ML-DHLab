---
title: "Prediction"
author: "<table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'><col width='10%'><col width='10%'>
  <tr style='border:none'>
    <td style='display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none' nowrap>
      <font style='font-style:normal'>Machine Learning with R</font><br>
      <a href='https://therbootcamp.github.io/ML-DHLab/'>
        <i class='fas fa-clock' style='font-size:.9em;' ></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <i class='fas fa-home' style='font-size:.9em;'></i>
      </a>
      <a href='mailto:therbootcamp@gmail.com'>
        <i class='fas fa-envelope' style='font-size: .9em;'></i>
      </a>
      <a href='https://www.linkedin.com/company/basel-r-bootcamp/'>
        <i class='fab fa-linkedin' style='font-size: .9em;'></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <font style='font-style:normal'>The R Bootcamp</font>
      </a>
    </td>
    <td style='width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none'>
      <img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
    </td>
  </tr></table>"
output:
  html_document:
    css: practical.css
    self_contained: no
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(comment = NA, 
                      fig.width = 6, 
                      fig.height = 6,
                      fig.align = 'center',
                      echo = TRUE, 
                      eval = TRUE, 
                      warning = FALSE,
                      message = FALSE)

options(digits = 3)
```

<p align="center">
<img width="100%" src="https://cdn-images-1.medium.com/max/1200/0*F0y1bmOEzCFCcPE_" margin=0><br>
<font style="font-size:10px">from [Medium.com](https://Medium.com/)</font>
</p>

# {.tabset}

## Overview

By the end of this practical you will know how to:

1. Fit regression, decision trees and random forests to training data.
2. Compare the fitting and prediction performance of two models for training and test data.

## Tasks

### A - Setup

1. Open your `TheRBootcamp` R project. 

2. Open a new R script. At the top of the script, using comments, write your name and the date. 

```{r, eval = FALSE, echo = TRUE}
## NAME
## DATE
## Prediction practical
```

3. Save it as a new file called `Prediction_practical.R` in the `2_Code` folder.  

4. Using `library()` load the packages `tidyverse`, `caret`, `party`, `partykit`.

```{r, eval = TRUE}
# Load packages necessary for this script
library(tidyverse)
library(caret)
library(party)
library(partykit)
```

5. Using `trainControl()`, create again the `ctrl_none` object with `method = "none"`.

```{r, echo = TRUE, eval = FALSE}
# Set training method to "none"
ctrl_none <- trainControl(method = "XX")
```

```{r}
# Set training method to "none"
ctrl_none <- trainControl(method = "none")
```

<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width=100%>
Dataset 1: <b>College graduation</b>
</p>


### B - Load the `graduation` data

1. Using `read_csv()`, read in the datasets `graduation_train.csv` and `graduation_test.csv`.

```{r, echo = TRUE, eval = TRUE}
# College data
college_train <- read_csv(file = "1_Data/college_train.csv")
college_test <- read_csv(file = "1_Data/college_test.csv")
```

2. Print the data sets to make sure everything's alright.

```{r}
# Print data sets to the console
college_train
college_test
```

3. Convert all character columns to factors in both training and test data using the code below. 

```{r, eval = TRUE, echo = TRUE}
# Convert all character features to factor
college_train <- college_train %>%
          mutate_if(is.character, factor)
college_test <- college_test %>%
          mutate_if(is.character, factor)
```

#### C - Fitting

#### Regression

1. Using `train()` fit a regression model called `graduation_glm` predicting `Grad.Rate`by all features. Specifically:

- for the `form` argument, use `Grad.Rate ~ .`.
- for the `data` argument, use  `college_train` in the data argument.
- for the `method` argument, use `method = "glm"` for regression.
- for the `trControl` argument, use your `ctrl_none` object you created above.

```{r, echo = TRUE, eval = FALSE}
# fit regression
graduation_glm <- train(form = XX ~ .,
                        data = XX,
                        method = "XX",
                        trControl = ctrl_none)
```


```{r}
graduation_glm <- train(form = Grad.Rate ~ .,
                        data = college_train,
                        method = "glm",
                        trControl = ctrl_none)
```

2. Explore your `graduation_glm` object by looking at `graduation_glm$finalModel` and using `summary()`. What does the output tell you?

```{r, eval = FALSE, echo = TRUE}
# show model
graduation_glm$XX
summary(XX)
```

```{r}
graduation_glm$finalModel
summary(graduation_glm)
```

3. Using `predict()` save the fitted values of `graduation_glm` object as `glm_fit`.

```{r, echo = TRUE, eval = FALSE}
# Save fitted values of regression model
glm_fit <- predict(XX)
```

```{r}
glm_fit <- predict(graduation_glm)
```

#### Decision Trees

4. Using `train()`, fit a decision tree model called `graduation_rpart` predicting `Grad.Rate`by all features. Specifically:

- for the `form` argument, use `Grad.Rate ~ .`.
- for the `data` argument, use  `college_train`.
- for the `method` argument, use `method = "rpart"` to create decision trees.
- for the `trControl` argument, use your `ctrl_none` object you created before.

```{r, echo = TRUE, eval = FALSE}
# fit decision tree
graduation_rpart <- train(form = XX ~ .,
                          data = XX,
                          method = "XX",
                          trControl = XX)  
```

```{r}
# fit decision tree
graduation_rpart <- train(form = Grad.Rate ~ .,
                          data = college_train,
                          method = "rpart",
                          trControl = ctrl_none) 
```

5. Explore your `graduation_rpart` object by looking at `graduation_rpart$finalModel` and plotting it with `plot(as.party(graduation_rpart$finalModel))`. What do you make of the output?

```{r}
graduation_rpart$finalModel
plot(as.party(graduation_rpart$finalModel))
```

6. Using `predict()`, save the fitted values of `graduation_rpart` object as `rpart_fit`.

```{r, echo = TRUE, eval = FALSE}
# Save fitted values of decision tree model
rpart_fit <- predict(XX)
```

```{r}
rpart_fit <- predict(graduation_rpart)
```

#### Random Forests

7. Using `train()`, fit a random forest model called `graduation_rf` predicting `Grad.Rate`by all features. Specifically:

- for the `form` argument, use `Grad.Rate ~ .`.
- for the `data` argument, use  `college_train`.
- for the `method` argument, use `method = "rf"` to fit random forests.
- for the `trControl` argument, use your `ctrl_none` object you created before.

```{r, echo = TRUE, eval = FALSE}
# fit random forest
graduation_rf <- train(form = XX ~ .,   
                 data = XX,
                 method = "XX",
                 trControl = XX)
```

```{r}
# fit random forest
graduation_rf <- train(form = Grad.Rate ~ ., 
                 data = college_train,
                 method = "rf",
                 trControl = ctrl_none)
```

8. Using `predict()`, save the fitted values of `graduation_rf` as `rf_fit`.

```{r, echo = TRUE, eval = FALSE}
# Save fitted values of random forest model
rf_fit <- predict(XX)
```

```{r}
rf_fit <- predict(graduation_rf)
```

#### Assess fitting accuracy

9. Save the true training criterion (`Grad.Rate`) in an object called `criterion_train`.

```{r, echo = TRUE, eval = FALSE}
# Store training criterion
criterion_train <- XX$XX
```

```{r}
# Store training criterion
criterion_train <- college_train$Grad.Rate
```

10. Using `postResample()`, determine the fitting performance of each of your models separately. Make sure to set your `criterion_train` values to the `obs` argument, and your true model fits `XX_fit` to the `pred` argument.

```{r, echo = TRUE, eval = FALSE}
# Regression accuracy
postResample(pred = XX, obs = XX)

# Decision tree accuracy
postResample(pred = XX, obs = XX)

# Random forest accuracy
postResample(pred = XX, obs = XX)
```

```{r}
# Regression accuracy
postResample(pred = glm_fit, obs = criterion_train)

# Decision tree accuracy
postResample(pred = rpart_fit, obs = criterion_train)

# Random forest accuracy
postResample(pred = rf_fit, obs = criterion_train)
```

11. What do you make of these results? Which model had the best fit?

### D - Prediction

1. Save the criterion values from the test data set as a new object called `criterion_test`.

```{r, echo = TRUE, eval = FALSE}
# Store test criterion
criterion_test <- XX$XX
```

```{r}
# Store test criterion
criterion_test <- college_test$Grad.Rate
```

2. Using `predict()`, calculate the predicted values of each model for the test data `college_test` as `glm_pred`, `rpart_pred` and `rf_pred`. 

```{r, echo = TRUE, eval = FALSE}
# Regression predicted values
glm_pred <- predict(XX, newdata = XX)

# Decision trees predicted values
rpart_pred <- predict(XX, newdata = XX)

# Random forests predicted values
rf_pred <- predict(XX, newdata = XX)
```

```{r}
# Regression predicted values
glm_pred <- predict(graduation_glm, newdata = college_test)

# Decision trees predicted values
rpart_pred <- predict(graduation_rpart, newdata = college_test)

# Random forests predicted values
rf_pred <- predict(graduation_rf, newdata = college_test)
```

3. Using `postResample()`, determine the prediction performance of each of your models for the test criterion `criterion_test`. 

```{r, echo = TRUE, eval = FALSE}
# Regression prediction performance
postResample(pred = XX, obs = XX)

# Decision trees prediction performance
postResample(pred = XX, obs = XX)

# Random forests prediction performance
postResample(pred = XX, obs = XX)
```

```{r}
# Regression prediction performance
postResample(pred = glm_pred, obs = criterion_test)

# Decision trees prediction performance
postResample(pred = rpart_pred, obs = criterion_test)

# Random forests prediction performance
postResample(pred = rf_pred, obs = criterion_test)
```

4. How does each model's prediction performance compare to its fitting performance? Is it worse? Better? The same? What does the change tell you about the models?

```{r}
# The regression goodness of fit stayed the most constant. The random forest one droped considerably.
```

5. Which of the three models has the best prediction performance?

```{r}
# The random forest predictions are still the most accurate.
```

6. If you had to use one of these three models in the real-world, which one would it be?

<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width=100%>
Dataset 2: <b>House sales</b>
</p>

### E - Load the `house` data

1. Create a section in your script by copying the template below.

```{r, echo = TRUE, eval = FALSE}
# House prices ------------------------------------------------------------
```

2. In this section you will analyze house sales data from King County, Washington. Run the code below to load the `house_train` and `house_test` datasets.

```{r, echo = TRUE}
# house data
house_train <- read_csv(file = "1_Data/house_train.csv")
house_test <- read_csv(file = "1_Data/house_test.csv")
```

3. Print the datasets to the console to get an idea of their contents. 

```{r}
# Print dataframes to the console
house_train
house_test
```

4. Again, a little bit of data cleaning. Convert all character features to factor.

```{r, echo = TRUE, eval = FALSE}
# Convert all character to factor
house_train <- house_train %>%
          mutate_if(is.character, factor)
house_test <- house_test %>%
          mutate_if(is.character, factor)
```

### F - Fitting

#### Regression

1. Using `train()`, fit a regression model called `price_glm` predicting the house sale price (`price`) using all features in `house_train`. Specifically:

- for the `form` argument, use `price ~ .`.
- for the `data` argument, use  `house_train`.
- for the `method` argument, use `method = "glm"` for regression.
- for the `trControl` argument, use your `ctrl_none` object you created in the beginning.

```{r}
# fit regression
price_glm <- train(form = price ~ .,
                   data = house_train,
                   method = "glm",
                   trControl = ctrl_none)
```

2. Explore your `price_glm` object by looking at `price_glm$finalModel` and using `summary()`. What do you find?

```{r}
price_glm$finalModel
summary(price_glm)
```

3. Using `predict()`, save the fitted values of `price_glm` object as `glm_fit`.

```{r}
# Store fitted values
glm_fit <- predict(price_glm)
```

#### Decision tree

4. Using `train()`, fit a decision tree model called `price_rpart` predicting `price` using all features in `house_train`. Specifically:

- for the `form` argument, use `price ~ .`.
- for the `data` argument, use  `house_train`.
- for the `method` argument, use `method = "rpart"` to create decision trees.
- for the `trControl` argument, use your `ctrl_none` object you created before.

```{r}
# fit decision tree
price_rpart <- train(form = price ~ .,
                     data = house_train,
                     method = "rpart",
                     trControl = ctrl_none) 
```

5. Explore your `price_rpart` object by looking at `price_rpart$finalModel` and plotting it with `plot(as.party(price_rpart$finalModel))`. What do you find?

```{r}
price_rpart$finalModel
plot(as.party(price_rpart$finalModel))
```

6. Using `predict()` save the fitted values of `price_rpart` object as `rpart_fit`.

```{r}
# Store fitted values
rpart_fit <- predict(price_rpart)
```

#### Random Forests

7. Using `train()`, fit a random forest model called `price_rf` predicting `price` using all features in `house_train`. Specifically:

- for the `form` argument, use `price ~ .`.
- for the `data` argument, use  `house_train` in the data argument.
- for the `method` argument, use `method = "rf"` to fit random forests.
- for the `trControl` argument, use your `ctrl_none` object you created before.

```{r}
price_rf <- train(form = price ~ .,
                 data = house_train,
                 method = "rf",
                 trControl = ctrl_none)
```


8. Using `predict()` save the fitted values of `price_rf` object as `rf_fit`.

```{r}
# store fitted values
rf_fit <- predict(price_rf)
```

#### Assess accuracy

9. Save the true training criterion values as a vector called `criterion_train`.

```{r}
# store criterion
criterion_train <- house_train$price
```

10. Using `postResample()`, determine the fitting performance of each of your models separately. 

```{r}
# Regression
postResample(pred = glm_fit, obs = criterion_train)

# Decision Trees
postResample(pred = rpart_fit, obs = criterion_train)

# Random Forests
postResample(pred = rf_fit, obs = criterion_train)
```

11. Which model had the best fit? Same model as for the graduation data?

### G - Prediction

1. Save the criterion values from the test data set as a new vector called `criterion_test`.

```{r}
# store criterion of test data
criterion_test <- house_test$price
```

2. Using `predict()`, save the predicted values of each model for the test data as `glm_pred`, `rpart_pred` and `rf_pred`. 

```{r}
# Regression
glm_pred <- predict(price_glm, 
                    newdata = house_test)

# Decision Trees
rpart_pred <- predict(price_rpart, 
                      newdata = house_test)

# Random Forests
rf_pred <- predict(price_rf, 
                   newdata = house_test)
```

3. Using `postResample()`, determine the prediction performance of each of your models. 

```{r}
# Regression
postResample(pred = glm_pred, obs = criterion_test)

# Decision Trees
postResample(pred = rpart_pred, obs = criterion_test)

# Random Forests
postResample(pred = rf_pred, obs = criterion_test)
```

4. How does each model's prediction performance compare to its fitting performance? Is it worse? Better? The same? What does the change tell you about the models?

5. Which of the three models has the best prediction performance?

6. Contemplate, if you had to use one of these three models in the real-world, which one would it be? Any different 

### X - Challenges: 

1. For either dataset try to find feature sets that lead to the best possible prediction performance. 

## Examples

```{r, eval = FALSE, echo = TRUE}
# Fitting and evaluating regression, decision trees, and random forests

# Step 0: Load packages-----------
library(tidyverse)    # Load tidyverse for dplyr and tidyr
library(caret)        # For ML mastery 
library(partykit)     # For decision trees
library(party)        # For decision trees

# Step 1: Load and Clean, and Explore Training data ----------------------

# training data
data_train <- read_csv("1_Data/mpg_train.csv")

# test data
data_test <- read_csv("1_Data/mpg_test.csv")

# Convert all characters to factor
#  Some ML models require factors
data_train <- data_train %>%
  mutate_if(is.character, factor)

data_test <- data_test %>%
  mutate_if(is.character, factor)

# Explore training data
data_train        # Print the dataset
View(data_train)  # Open in a new spreadsheet-like window 
dim(data_train)   # Print dimensions
names(data_train) # Print the names

# Define criterion_train
#   We'll use this later to evaluate model accuracy
criterion_train <- data_train$hwy

# Step 2: Define training control parameters -------------

# In this case, I will set method = "none" to fit to 
#  the entire dataset without any fancy methods
ctrl_none <- trainControl(method = "none") 

# Step 3: Train model: -----------------------------
#   Criterion: hwy
#   Features: year, cyl, displ

# Regression --------------------------
hwy_glm <- train(form = hwy ~ year + cyl + displ,
                 data = data_train,
                 method = "glm",
                 trControl = ctrl_none)

# Look at summary information
hwy_glm$finalModel
summary(hwy_glm)

# Save fitted values
glm_fit <- predict(hwy_glm)

#  Calculate fitting accuracies
postResample(pred = glm_fit, 
             obs = criterion_train)

# Decision Trees ----------------
hwy_rpart <- train(form = hwy ~ year + cyl + displ,
                data = data_train,
                method = "rpart",
                trControl = ctrl_none)

# Look at summary information
hwy_rpart$finalModel
plot(as.party(hwy_rpart$finalModel))   # Visualise your trees

# Save fitted values
rpart_fit <- predict(hwy_rpart)

# Calculate fitting accuracies
postResample(pred = rpart_fit, obs = criterion_train)

# Random Forests -------------------------
hwy_rf <- train(form = hwy ~ year + cyl + displ,
                data = data_train,
                method = "rf",
                trControl = ctrl_none)   

# Look at summary information
hwy_rf$finalModel

# Save fitted values
rf_fit <- predict(hwy_rf)

# Calculate fitting accuracies
postResample(pred = rf_fit, obs = criterion_train)

# Visualise Accuracy -------------------------

# Tidy competition results
accuracy <- tibble(criterion_train = criterion_train,
                   Regression = glm_fit,
                   DecisionTrees = rpart_fit,
                   RandomForest = rf_fit) %>%
               gather(model, prediction, -criterion_train) %>%
               # Add error measures
               mutate(se = prediction - criterion_train,
                      ae = abs(prediction - criterion_train))

# Calculate summaries
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # Calculate MAE (mean absolute error)

# Plot A) Scatterplot of truth versus predictions
ggplot(data = accuracy,
       aes(x = criterion_train, y = prediction, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = "Predicting mpg$hwy",
       subtitle = "Black line indicates perfect performance")

# Plot B) Violin plot of absolute errors
ggplot(data = accuracy, 
       aes(x = model, y = ae, fill = model)) + 
  geom_violin() + 
  geom_jitter(width = .05, alpha = .2) +
  labs(title = "Fitting Absolute Errors",
       subtitle = "Numbers indicate means",
       x = "Model",
       y = "Absolute Error") +
  guides(fill = FALSE) +
  annotate(geom = "label", 
           x = accuracy_agg$model, 
           y = accuracy_agg$mae, 
           label = round(accuracy_agg$mae, 2))

# Step 5: Access prediction ------------------------------

# Define criterion_train
criterion_test <- data_test$hwy

# Save predicted values
glm_pred <- predict(hwy_glm, newdata = data_test)
rpart_pred <- predict(hwy_rpart, newdata = data_test)
rf_pred <- predict(hwy_rf, newdata = data_test)

#  Calculate fitting accuracies
postResample(pred = glm_pred, obs = criterion_test)
postResample(pred = rpart_pred, obs = criterion_test)
postResample(pred = rf_pred, obs = criterion_test)

# Visualise Accuracy -------------------------

# Tidy competition results
accuracy <- tibble(criterion_test = criterion_test,
                   Regression = glm_pred,
                   DecisionTrees = rpart_pred,
                   RandomForest = rf_pred) %>%
               gather(model, prediction, -criterion_test) %>%
               # Add error measures
               mutate(se = prediction - criterion_test,
                      ae = abs(prediction - criterion_test))

# Calculate summaries
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # Calculate MAE (mean absolute error)

# Plot A) Scatterplot of truth versus predictions
ggplot(data = accuracy,
       aes(x = criterion_test, y = prediction, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = "Predicting mpg$hwy",
       subtitle = "Black line indicates perfect performance")

# Plot B) Violin plot of absolute errors
ggplot(data = accuracy, 
       aes(x = model, y = ae, fill = model)) + 
  geom_violin() + 
  geom_jitter(width = .05, alpha = .2) +
  labs(title = "Prediction Absolute Errors",
       subtitle = "Numbers indicate means",
       x = "Model",
       y = "Absolute Error") +
  guides(fill = FALSE) +
  annotate(geom = "label", 
           x = accuracy_agg$model, 
           y = accuracy_agg$mae, 
           label = round(accuracy_agg$mae, 2))
```


## Datasets

```{r, eval = TRUE, message = FALSE, echo = FALSE}
library(tidyverse)
library(ggthemes)
```

|File  |Rows | Columns |
|:----|:-----|:------|
|[college_train.csv](https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_train.csv)| 500 | 18|
|[college_test.csv](https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_test.csv)| 277 | 18|
|[house_train.csv](https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/house_train.csv)| 5000 | 21|
|[house_test.csv](https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/house_test.csv)| 1000 | 21|

- The `college_train` and `college_test` data are taken from the `College` dataset in the `ISLR` package. They contain statistics for a large number of US Colleges from the 1995 issue of US News and World Report.

- The `house_train` and `house_test` data come from [https://www.kaggle.com/harlfoxem/housesalesprediction](https://www.kaggle.com/harlfoxem/housesalesprediction)

#### Variable description of `college_train` and `college_test`

| Name | Description |
|:-------------|:-------------------------------------|
| `Private` | A factor with levels No and Yes indicating private or public university. |
| `Apps` | Number of applications received.  |
| `Accept` | Number of applications accepted. |
| `Enroll` | Number of new students enrolled. |
| `Top10perc` | Pct. new students from top 10% of H.S. class. |
| `Top25perc` | Pct. new students from top 25% of H.S. class. |
| `F.Undergrad` | Number of fulltime undergraduates. |
| `P.Undergrad` | Number of parttime undergraduates. |
| `Outstate` | Out-of-state tuition. |
| `Room.Board` | Room and board costs. |
| `Books` | Estimated book costs. |
| `Personal` | Estimated personal spending. |
| `PhD` | Pct. of faculty with Ph.D.'s. |
| `Terminal` | Pct. of faculty with terminal degree. |
| `S.F.Ratio` | Student/faculty ratio. |
| `perc.alumni` | Pct. alumni who donate. |
| `Expend` | Instructional expenditure per student. |
| `Grad.Rate` | Graduation rate. |

#### Variable description of `house_train` and `house_test`

| Name | Description |
|:-------------|:-------------------------------------|
| `price` | Price of the house in $. |
| `bedrooms` | Number of bedrooms.  |
| `bathrooms` | Number of bathrooms. |
| `sqft_living` | Square footage of the home. |
| `sqft_lot` | Square footage of the lot. |
| `floors` | Total floors (levels) in house. |
| `waterfront` | House which has a view to a waterfront. |
| `view` | Has been viewed. |
| `condition` | How good the condition is (Overall). |
| `grade` | Overall grade given to the housing unit, based on King County grading system. |
| `sqft_above` | Square footage of house apart from basement. |
| `sqft_basement` | Square footage of the basement. |
| `yr_built` | Built Year. |
| `yr_renovated` | Year when house was renovated. |
| `zipcode` | Zip code. |
| `lat` | Latitude coordinate. |
| `long` | Longitude coordinate. |
| `sqft_living15` | Living room area in 2015 (implies some renovations). This might or might not have affected the lotsize area. |
| `sqft_lot15` | lot-size area in 2015 (implies some renovations). |


## Functions

### Packages

|Package| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|
|`caret`|`install.packages("caret")`|
|`partykit`|`install.packages("partykit")`|
|`party`|`install.packages("party")`|

### Functions

| Function| Package | Description |
|:---|:------|:---------------------------------------------|
| `trainControl()`|`caret`|    Define modelling control parameters| 
| `train()`|`caret`|    Train a model|
| `predict(object, newdata)`|`stats`|    Predict the criterion values of `newdata` based on `object`|
| `postResample()`|`caret`|   Calculate aggregate model performance in regression tasks|
| `confusionMatrix()`|`caret`|   Calculate aggregate model performance in classification tasks| 

## Resources

### Cheatsheet

<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf">
  <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%"></a><br>
 <font style="font-size:10px"> from <a href= "https://github.com/rstudio/cheatsheets/raw/master/caret.pdf</figcaption">github.com/rstudio</a></font>
</figure>

