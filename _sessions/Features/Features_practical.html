<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Features</title>

<script src="Features_practical_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Features_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Features_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Features_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Features_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Features_practical_files/navigation-1.1/tabsets.js"></script>
<link href="Features_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Features_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="practical.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Features</h1>
<h4 class="author"><table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'>
<col width='10%'>
<col width='10%'>
<tr style="border:none">
<td style="display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none" nowrap>
<font style='font-style:normal'>Machine Learning with R</font><br> <a href='https://therbootcamp.github.io/ML-DHLab/'> <i class='fas fa-clock' style='font-size:.9em;' ></i> </a> <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;'></i> </a> <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a> <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a> <a href='https://therbootcamp.github.io'> <font style='font-style:normal'>The R Bootcamp</font> </a>
</td>
<td style="width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none">
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
</td>
</tr>
</table></h4>

</div>


<p align="center">
<img width="100%" src="image/wrongdata.gif" margin=0> <br> from <font style="font-size:10px">from <a href="https://dilbert.com/">dilbert.com</a></font>
</p>
<div id="section" class="section level1 tabset">
<h1></h1>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>By the end of this practical you will:</p>
<ol style="list-style-type: decimal">
<li>Understand the importance of the curse of dimensionality.</li>
<li>Know how to eliminate unwanted features.</li>
<li>Explore and use feature importance.</li>
<li>Use dimensionality reduction.</li>
</ol>
</div>
<div id="tasks" class="section level2">
<h2>Tasks</h2>
<div id="a---setup" class="section level3">
<h3>A - Setup</h3>
<ol style="list-style-type: decimal">
<li><p>Open your <code>TheRBootcamp</code> R project.</p></li>
<li><p>Open a new R script. At the top of the script, using comments, write your name and the date. Save it as a new file called <code>Features_practical.R</code> in the <code>2_Code</code> folder.</p></li>
<li><p>Using <code>library()</code> load <code>tidyverse</code> and <code>caret</code>.</p></li>
</ol>
<pre class="r"><code># Load packages
library(tidyverse)
library(caret)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Using the code below load the data sets used in this practical and turn all character into factor.</li>
</ol>
<pre class="r"><code># Pima Indians diabetes
pima_diabetes &lt;- read_csv(file = &quot;1_Data/pima_diabetes.csv&quot;) %&gt;% 
  mutate_if(is.character, as_factor)

# murders crime statistics
murders_crime &lt;- read_csv(file = &quot;1_Data/murders_crime.csv&quot;)%&gt;% 
  mutate_if(is.character, as_factor)

# (Non-) violent crime statistics
violent_crime &lt;- read_csv(file = &quot;1_Data/violent_crime.csv&quot;)%&gt;% 
  mutate_if(is.character, as_factor)
nonviolent_crime &lt;- read_csv(file = &quot;1_Data/nonviolent_crime.csv&quot;)%&gt;% 
  mutate_if(is.character, as_factor)</code></pre>
</div>
<div id="b---pima-indians-diabetes" class="section level3">
<h3>B - Pima Indians Diabetes</h3>
<p>In this section, you will explore feature selection for the Pima Indians Diabetes data set. The Pima are a group of Native Americans living in Arizona. A genetic predisposition allowed this group to live well with a diet poor of carbohydrates for years. In the recent years, however, because of a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, they developed a high prevalence of type 2 diabetes. For this reason they have been subject of many studies.</p>
<ol style="list-style-type: decimal">
<li>Print <code>pima_diabetes</code> to take a look and familiarize yourself with the data.</li>
</ol>
<pre class="r"><code>pima_diabetes</code></pre>
<pre><code># A tibble: 724 x 7
   diabetes pregnant glucose pressure  mass pedigree   age
   &lt;fct&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
 1 pos             6     148       72  33.6    0.627    50
 2 neg             1      85       66  26.6    0.351    31
 3 pos             8     183       64  23.3    0.672    32
 4 neg             1      89       66  28.1    0.167    21
 5 pos             0     137       40  43.1    2.29     33
 6 neg             5     116       74  25.6    0.201    30
 7 pos             3      78       50  31      0.248    26
 8 pos             2     197       70  30.5    0.158    53
 9 neg             4     110       92  37.6    0.191    30
10 pos            10     168       74  38      0.537    34
# … with 714 more rows</code></pre>
<div id="splitting" class="section level4">
<h4>Splitting</h4>
<ol start="2" style="list-style-type: decimal">
<li>Before you begin, you need to separate the hold-out (test) data set for later. Create <code>pima_train</code> and <code>pima_test</code> using the <code>createDataPartition()</code> function. Set <code>p = .15</code> to select (only) <b>15% of cases for the training set</b>. The criterion is <code>diabetes</code>. See code below.</li>
</ol>
<pre class="r"><code># seed
set.seed(100)

# split index
train_index &lt;- createDataPartition(XX$XX, p = .15, list = FALSE)

# train and test sets
pima_train &lt;- XX %&gt;% slice(train_index)
pima_test  &lt;- XX %&gt;% slice(-train_index)</code></pre>
<pre class="r"><code># seed
set.seed(100)

# split index
train_index &lt;- createDataPartition(pima_diabetes$diabetes, p = .15, list = FALSE)

# train and test sets
pima_train &lt;- pima_diabetes %&gt;% slice(train_index)
pima_test  &lt;- pima_diabetes %&gt;% slice(-train_index)</code></pre>
</div>
<div id="remove-unwanted-features" class="section level4">
<h4>Remove unwanted features</h4>
<p>OK, let’s get to work and remove some features from the training data.</p>
<ol start="3" style="list-style-type: decimal">
<li>First split the training data into a data frame holding the predictors and a vector holding the criterion (<code>diabetes</code>) using the template below.</li>
</ol>
<pre class="r"><code># Select predictors
pima_train_pred &lt;- pima_train %&gt;% select(-XX)

# Select criterion
pima_train_crit &lt;- pima_train %&gt;% select(XX)</code></pre>
<pre class="r"><code># Select predictors
pima_train_pred &lt;- pima_train %&gt;% select(-diabetes)

# Select criterion
pima_train_crit &lt;- pima_train %&gt;% select(diabetes)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Although, use the template below to test whether there are any excessively correlated features using <code>cor()</code> and <code>findCorrelation()</code>. Are there any?</li>
</ol>
<pre class="r"><code># determine correlation matrix
corr_matrix &lt;- cor(XX_pred)

# find excessively correlated variables
findCorrelation(corr_matrix)</code></pre>
<pre class="r"><code># determine correlation matrix
corr_matrix &lt;- cor(pima_train_pred)

# find excessively correlated variables
findCorrelation(corr_matrix)</code></pre>
<pre><code>integer(0)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Now, test if there are any near-zero variance features using the <code>nearZeroVar</code> function. Any of those?</li>
</ol>
<pre class="r"><code># find near zero variance predictors
nearZeroVar(XX_pred)</code></pre>
<pre class="r"><code># find near zero variance predictors
nearZeroVar(pima_train_pred)</code></pre>
<pre><code>integer(0)</code></pre>
</div>
<div id="feature-importance" class="section level4">
<h4>Feature importance</h4>
<p>As there were no problems with the features in the data set, you have retained all of them. In this section, you will carry out feature selection on the grounds of feature importance. To do this, you first have to fit a model on the basis of which feature importance can be determined. How about a simple logistic regression using <code>method = "glm"</code>?</p>
<ol start="6" style="list-style-type: decimal">
<li>Fit a <code>glm</code> model to the training data predicting <code>diabetes</code>. Call the model <code>pima_glm</code>.</li>
</ol>
<pre class="r"><code># fit regression
pima_glm &lt;- train(diabetes ~ .,
                data = XX,
                method = XX,
                trControl = trainControl(method = &#39;none&#39;))</code></pre>
<pre class="r"><code># fit regression
pima_glm &lt;- train(diabetes ~ .,
                data = pima_train,
                method = &quot;glm&quot;,
                trControl = trainControl(method = &#39;none&#39;))</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Evaluate feature importance using <code>varImp()</code>. The function will show importance on a scale from 0 (least important feature) to 100 (most important feature). You can set <code>scale = TRUE</code> to see absolute importance measures scaled as <em>t</em>-values.</li>
</ol>
<pre class="r"><code># determine variable importance
varimp_glm &lt;- varImp(XX)

# print variable importance
varimp_glm

# print variable importance
plot(varimp_glm)</code></pre>
<pre class="r"><code># determine variable importance
varimp_glm &lt;- varImp(pima_glm)

# print variable importance
varimp_glm</code></pre>
<pre><code>glm variable importance

         Overall
glucose    100.0
mass        90.8
pregnant    36.9
pressure    35.1
pedigree    33.8
age          0.0</code></pre>
<pre class="r"><code># print variable importance
plot(varimp_glm)</code></pre>
<p><img src="Features_practical_files/figure-html/unnamed-chunk-16-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="model-comparison" class="section level4">
<h4>Model comparison</h4>
<p>Now, create a second model using the best features and compare performances.</p>
<ol start="8" style="list-style-type: decimal">
<li>Fit the glm a second time, this time using only the four best features and store the result in a different fit object.</li>
</ol>
<pre class="r"><code># fit glm with best four features
pima_glm4 &lt;- train(diabetes ~ XX + YY + ZZ + AA,
                data = XX,
                method = XX)</code></pre>
<pre class="r"><code># fit glm with best four features
pima_glm4 &lt;- train(diabetes ~ glucose + mass + pregnant + pressure,
                data = pima_train,
                method = &quot;glm&quot;)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>For both models, the glm using all and the glm using just four features, predict the criterion in the test data and evaluate the prediction performance using <code>confusionMatrix()</code>. Which model model is better?</li>
</ol>
<pre class="r"><code># determine predictions for test data
pima_glm_pred &lt;- predict(XX, newdata = XX)
pima_glm4_pred &lt;- predict(XX, newdata = XX)

# evaluate the results
confusionMatrix(XX, reference = XX)
confusionMatrix(XX, reference = XX)</code></pre>
<pre class="r"><code># determine predictions for test data
pima_glm_pred &lt;- predict(pima_glm, newdata = pima_test)
pima_glm4_pred &lt;- predict(pima_glm4, newdata = pima_test)

# evaluate the results
confusionMatrix(pima_glm_pred, pima_test$diabetes)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction pos neg
       pos 109  51
       neg 102 352
                                        
               Accuracy : 0.751         
                 95% CI : (0.715, 0.785)
    No Information Rate : 0.656         
    P-Value [Acc &gt; NIR] : 2.70e-07      
                                        
                  Kappa : 0.414         
                                        
 Mcnemar&#39;s Test P-Value : 5.29e-05      
                                        
            Sensitivity : 0.517         
            Specificity : 0.873         
         Pos Pred Value : 0.681         
         Neg Pred Value : 0.775         
             Prevalence : 0.344         
         Detection Rate : 0.178         
   Detection Prevalence : 0.261         
      Balanced Accuracy : 0.695         
                                        
       &#39;Positive&#39; Class : pos           
                                        </code></pre>
<pre class="r"><code>confusionMatrix(pima_glm4_pred, pima_test$diabetes)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction pos neg
       pos 113  44
       neg  98 359
                                        
               Accuracy : 0.769         
                 95% CI : (0.733, 0.802)
    No Information Rate : 0.656         
    P-Value [Acc &gt; NIR] : 9.36e-10      
                                        
                  Kappa : 0.454         
                                        
 Mcnemar&#39;s Test P-Value : 8.68e-06      
                                        
            Sensitivity : 0.536         
            Specificity : 0.891         
         Pos Pred Value : 0.720         
         Neg Pred Value : 0.786         
             Prevalence : 0.344         
         Detection Rate : 0.184         
   Detection Prevalence : 0.256         
      Balanced Accuracy : 0.713         
                                        
       &#39;Positive&#39; Class : pos           
                                        </code></pre>
<ol start="10" style="list-style-type: decimal">
<li><p>You should have observed that the model with two fewer features is actually slightly better than the full model. Why do you think this is the case?</p></li>
<li><p>Play around: Increase the proportion of data dedicated to training or use a different model, e.g., <code>random forest</code>, and see whether things change.</p></li>
</ol>
</div>
</div>
<div id="c---murders" class="section level3">
<h3>C - Murders</h3>
<p>Now explore feature selection using a different data set. The data used in this section combines socio-economic data from the US ’90 Census, data from Law Enforcement Management and Admin Stats survey, and crime data from the FB. The gaol is to predict <code>murders</code> (the criterion in this section).</p>
<ol style="list-style-type: decimal">
<li>Print <code>murders_crime</code> and familiarize yourself with the data.</li>
</ol>
<pre class="r"><code>murders_crime</code></pre>
<pre><code># A tibble: 1,823 x 102
   murders population householdsize racepctblack racePctWhite racePctAsian
   &lt;fct&gt;        &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;
 1 yes          27591          2.63         0.17         94.8         1.6 
 2 yes          36830          2.6         42.4          53.7         0.54
 3 yes          23928          2.6         11.0          81.3         1.78
 4 no           15675          2.59         4.08         84.1         0.54
 5 yes          96086          3.19         8.54         59.8        17.2 
 6 no           48622          2.44         3.14         95.5         0.77
 7 no           10444          3.02         0.41         98.9         0.39
 8 yes         222103          2.49        11.4          82.4         3.77
 9 no           15535          2.35        14.9          84.6         0.32
10 yes          24664          2.73        13.7          85.0         0.53
# … with 1,813 more rows, and 96 more variables: racePctHisp &lt;dbl&gt;,
#   agePct12t21 &lt;dbl&gt;, agePct12t29 &lt;dbl&gt;, agePct16t24 &lt;dbl&gt;, agePct65up &lt;dbl&gt;,
#   numbUrban &lt;dbl&gt;, pctUrban &lt;dbl&gt;, medIncome &lt;dbl&gt;, pctWWage &lt;dbl&gt;,
#   pctWFarmSelf &lt;dbl&gt;, pctWInvInc &lt;dbl&gt;, pctWSocSec &lt;dbl&gt;, pctWPubAsst &lt;dbl&gt;,
#   pctWRetire &lt;dbl&gt;, medFamInc &lt;dbl&gt;, perCapInc &lt;dbl&gt;, whitePerCap &lt;dbl&gt;,
#   blackPerCap &lt;dbl&gt;, indianPerCap &lt;dbl&gt;, AsianPerCap &lt;dbl&gt;, HispPerCap &lt;dbl&gt;,
#   NumUnderPov &lt;dbl&gt;, PctPopUnderPov &lt;dbl&gt;, PctLess9thGrade &lt;dbl&gt;,
#   PctNotHSGrad &lt;dbl&gt;, PctBSorMore &lt;dbl&gt;, PctUnemployed &lt;dbl&gt;,
#   PctEmploy &lt;dbl&gt;, PctEmplManu &lt;dbl&gt;, PctEmplProfServ &lt;dbl&gt;,
#   PctOccupManu &lt;dbl&gt;, PctOccupMgmtProf &lt;dbl&gt;, MalePctDivorce &lt;dbl&gt;,
#   MalePctNevMarr &lt;dbl&gt;, FemalePctDiv &lt;dbl&gt;, TotalPctDiv &lt;dbl&gt;,
#   PersPerFam &lt;dbl&gt;, PctFam2Par &lt;dbl&gt;, PctKids2Par &lt;dbl&gt;,
#   PctYoungKids2Par &lt;dbl&gt;, PctTeen2Par &lt;dbl&gt;, PctWorkMomYoungKids &lt;dbl&gt;,
#   PctWorkMom &lt;dbl&gt;, NumKidsBornNeverMar &lt;dbl&gt;, PctKidsBornNeverMar &lt;dbl&gt;,
#   NumImmig &lt;dbl&gt;, PctImmigRecent &lt;dbl&gt;, PctImmigRec5 &lt;dbl&gt;,
#   PctImmigRec8 &lt;dbl&gt;, PctImmigRec10 &lt;dbl&gt;, PctRecentImmig &lt;dbl&gt;,
#   PctRecImmig5 &lt;dbl&gt;, PctRecImmig8 &lt;dbl&gt;, PctRecImmig10 &lt;dbl&gt;,
#   PctSpeakEnglOnly &lt;dbl&gt;, PctNotSpeakEnglWell &lt;dbl&gt;, PctLargHouseFam &lt;dbl&gt;,
#   PctLargHouseOccup &lt;dbl&gt;, PersPerOccupHous &lt;dbl&gt;, PersPerOwnOccHous &lt;dbl&gt;,
#   PersPerRentOccHous &lt;dbl&gt;, PctPersOwnOccup &lt;dbl&gt;, PctPersDenseHous &lt;dbl&gt;,
#   PctHousLess3BR &lt;dbl&gt;, MedNumBR &lt;dbl&gt;, HousVacant &lt;dbl&gt;, PctHousOccup &lt;dbl&gt;,
#   PctHousOwnOcc &lt;dbl&gt;, PctVacantBoarded &lt;dbl&gt;, PctVacMore6Mos &lt;dbl&gt;,
#   MedYrHousBuilt &lt;dbl&gt;, PctHousNoPhone &lt;dbl&gt;, PctWOFullPlumb &lt;dbl&gt;,
#   OwnOccLowQuart &lt;dbl&gt;, OwnOccMedVal &lt;dbl&gt;, OwnOccHiQuart &lt;dbl&gt;,
#   OwnOccQrange &lt;dbl&gt;, RentLowQ &lt;dbl&gt;, RentMedian &lt;dbl&gt;, RentHighQ &lt;dbl&gt;,
#   RentQrange &lt;dbl&gt;, MedRent &lt;dbl&gt;, MedRentPctHousInc &lt;dbl&gt;,
#   MedOwnCostPctInc &lt;dbl&gt;, MedOwnCostPctIncNoMtg &lt;dbl&gt;, NumInShelters &lt;dbl&gt;,
#   NumStreet &lt;dbl&gt;, PctForeignBorn &lt;dbl&gt;, PctBornSameState &lt;dbl&gt;,
#   PctSameHouse85 &lt;dbl&gt;, PctSameCity85 &lt;dbl&gt;, PctSameState85 &lt;dbl&gt;,
#   LandArea &lt;dbl&gt;, PopDens &lt;dbl&gt;, PctUsePubTrans &lt;dbl&gt;,
#   LemasPctOfficDrugUn &lt;dbl&gt;</code></pre>
<div id="splitting-1" class="section level4">
<h4>Splitting</h4>
<ol start="2" style="list-style-type: decimal">
<li>Create <code>murders_train</code> and <code>murders_test</code> using <code>createDataPartition()</code> with (only) <b>25% of cases going into the training set</b>.</li>
</ol>
<pre class="r"><code># split index
train_index &lt;- createDataPartition(murders_crime$murders, p = .25, list = FALSE)

# train and test sets
murders_train &lt;- murders_crime %&gt;% slice(train_index)
murders_test  &lt;- murders_crime %&gt;% slice(-train_index)</code></pre>
</div>
<div id="remove-unwanted-features-1" class="section level4">
<h4>Remove unwanted features</h4>
<ol start="3" style="list-style-type: decimal">
<li>Before removing unwanted features from the training set, split the training data into predictors and the criterion in the same way you have done this above.</li>
</ol>
<pre class="r"><code># Select predictors
murders_train_pred &lt;- murders_train %&gt;% select(-murders)

# Select criterion
murders_train_crit &lt;- murders_train %&gt;% select(murders)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Test if there are any excessively correlated features using <code>cor()</code> and <code>findCorrelation()</code>. Are there any this time?</li>
</ol>
<pre class="r"><code># determine correlation matrix
corr_matrix &lt;- cor(murders_train_pred)

# find excessively correlated variables
findCorrelation(corr_matrix)</code></pre>
<pre><code> [1] 11 17 27 30 41 44 48 49 53 54 55 57 58 59 60 61 63 64 65 68 71 80 81 84 85
[26] 87 93  7  8 14 13 20 21 31 38 43  1 62 42 67 51</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Using the code below, remove the excessively correlated features from the training predictor set.</li>
</ol>
<pre class="r"><code># remove features
murders_train_pred &lt;- murders_train_pred %&gt;% select(- XX)</code></pre>
<pre class="r"><code># remove features
murders_train_pred &lt;- murders_train_pred %&gt;% 
  select(-findCorrelation(corr_matrix))</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Test if there are any near-zero variance features. Any of those this time?</li>
</ol>
<pre class="r"><code># find near zero variance predictors
nearZeroVar(murders_train_pred)</code></pre>
<pre><code>integer(0)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>You should have found that there were plenty of excessively correlated features but no near-zero variance features. Provided that you excluded the former, bind the reduced predictor set back together with the criterion into a new, clean version of the training set. See template below.</li>
</ol>
<pre class="r"><code># clean training set
murders_train_clean &lt;- XX %&gt;% 
  bind_cols(XX)</code></pre>
<pre class="r"><code># combine clean predictor set with criterion
murders_train_clean &lt;- murders_train_pred %&gt;% 
  bind_cols(murders_train_crit)</code></pre>
</div>
<div id="model-comparison-1" class="section level4">
<h4>Model comparison</h4>
<ol start="8" style="list-style-type: decimal">
<li>Let us find out whether excluding some of the highly correlated features matters. Fit a <code>glm</code> twice, once using the original training set and once using the clean training set, and store the fits in separate objects. See template below.</li>
</ol>
<pre class="r"><code># fit glm
murders_glm &lt;- train(murders ~ .,
                     data = XX,
                     method = &quot;glm&quot;,
                     trControl = trainControl(method = &#39;none&#39;))

# fit glm with clean data
murders_glm_clean &lt;- train(murders ~ .,
                           data = XX,
                           method = &quot;glm&quot;,
                           trControl = trainControl(method = &#39;none&#39;))</code></pre>
<pre class="r"><code># fit glm
murders_glm &lt;- train(murders ~ .,
                     data = murders_train,
                     method = &quot;glm&quot;,
                     trControl = trainControl(method = &#39;none&#39;))

# fit glm with clean data
murders_glm_clean &lt;- train(murders ~ .,
                           data = murders_train_clean,
                           method = &quot;glm&quot;,
                           trControl = trainControl(method = &#39;none&#39;))</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>You probably have noticed warning messages. They could indicate that the features in both data sets, but especially the non-clean set, are still too highly correlated. Go ahead nonetheless and evaluate the performance on the hold-out set. Which set of features predicts better?</li>
</ol>
<pre class="r"><code># determine predictions for test data
murders_pred &lt;- predict(murders_glm, newdata = murders_test)
murders_clean_pred &lt;- predict(murders_glm_clean, newdata = murders_test)

# evaluate the results
confusionMatrix(murders_pred, murders_test$murders)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction yes  no
       yes 549 201
       no  188 429
                                        
               Accuracy : 0.715         
                 95% CI : (0.691, 0.739)
    No Information Rate : 0.539         
    P-Value [Acc &gt; NIR] : &lt;2e-16        
                                        
                  Kappa : 0.427         
                                        
 Mcnemar&#39;s Test P-Value : 0.543         
                                        
            Sensitivity : 0.745         
            Specificity : 0.681         
         Pos Pred Value : 0.732         
         Neg Pred Value : 0.695         
             Prevalence : 0.539         
         Detection Rate : 0.402         
   Detection Prevalence : 0.549         
      Balanced Accuracy : 0.713         
                                        
       &#39;Positive&#39; Class : yes           
                                        </code></pre>
<pre class="r"><code>confusionMatrix(murders_clean_pred, murders_test$murders)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction yes  no
       yes 548 193
       no  189 437
                                        
               Accuracy : 0.721         
                 95% CI : (0.696, 0.744)
    No Information Rate : 0.539         
    P-Value [Acc &gt; NIR] : &lt;2e-16        
                                        
                  Kappa : 0.437         
                                        
 Mcnemar&#39;s Test P-Value : 0.878         
                                        
            Sensitivity : 0.744         
            Specificity : 0.694         
         Pos Pred Value : 0.740         
         Neg Pred Value : 0.698         
             Prevalence : 0.539         
         Detection Rate : 0.401         
   Detection Prevalence : 0.542         
      Balanced Accuracy : 0.719         
                                        
       &#39;Positive&#39; Class : yes           
                                        </code></pre>
</div>
<div id="data-compression-with-pca" class="section level4">
<h4>Data compression with PCA</h4>
<ol start="10" style="list-style-type: decimal">
<li>Given the high features correlations, it could be sensible to compress the data using <code>principal component analysis</code> (PCA). Create a third glm model using the original, full training set and this time add <code>preProcess = c('pca')</code> and <code>preProcOptions = list(thresh = 0.8)</code> in <code>trControl</code>. These additional settings instruct caret to extract new features from the data using PCA and to retain only as many features as are needed to capture 80% of the original variance.</li>
</ol>
<pre class="r"><code># fit glm with preprocessed features
murders_glm_pca = train(murders ~ .,
                        data = murders_train,
                        method = &quot;glm&quot;,
                        preProcess = c(&quot;pca&quot;),
                        trControl = trainControl(method = &#39;none&#39;,
                                                 preProcOptions = list(thresh = 0.8)))</code></pre>
<ol start="11" style="list-style-type: decimal">
<li>Compare the prediction performance to the previous two models.</li>
</ol>
<pre class="r"><code># determine predictions for test data
murders_pca &lt;- predict(murders_glm_pca, newdata = murders_test)

# evaluate the results
confusionMatrix(murders_pca, murders_test$murders)</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction yes  no
       yes 553 144
       no  184 486
                                        
               Accuracy : 0.76          
                 95% CI : (0.737, 0.782)
    No Information Rate : 0.539         
    P-Value [Acc &gt; NIR] : &lt;2e-16        
                                        
                  Kappa : 0.519         
                                        
 Mcnemar&#39;s Test P-Value : 0.0313        
                                        
            Sensitivity : 0.750         
            Specificity : 0.771         
         Pos Pred Value : 0.793         
         Neg Pred Value : 0.725         
             Prevalence : 0.539         
         Detection Rate : 0.405         
   Detection Prevalence : 0.510         
      Balanced Accuracy : 0.761         
                                        
       &#39;Positive&#39; Class : yes           
                                        </code></pre>
<ol start="12" style="list-style-type: decimal">
<li>Play around: Alter the amount of variance explained by the <code>PCA</code> (using <code>thresh</code>), increase the proportion dedicated to training, use a different model, e.g., <code>random forest</code>, and see whether things change.</li>
</ol>
</div>
<div id="feature-importance-1" class="section level4">
<h4>Feature importance</h4>
<ol start="13" style="list-style-type: decimal">
<li>Now find out which features are actually most important for predicting murders. Using <code>varImp()</code>, evaluate the feature importance for each of the three models used in the previous section.</li>
</ol>
<pre class="r"><code># determine variable importance
varimp_glm &lt;- varImp(murders_glm)
varimp_glm_clean &lt;- varImp(murders_glm_clean)
varimp_glm_pca &lt;- varImp(murders_glm_pca)

# print variable importance
varimp_glm</code></pre>
<pre><code>glm variable importance

  only 20 most important variables shown (out of 99)

                      Overall
MalePctNevMarr          100.0
PctVacantBoarded         77.7
OwnOccHiQuart            75.4
NumKidsBornNeverMar      73.1
population               72.9
indianPerCap             70.0
PctPopUnderPov           63.9
PctLess9thGrade          62.8
HispPerCap               62.2
PctSpeakEnglOnly         61.9
NumUnderPov              60.9
PctVacMore6Mos           60.9
RentMedian               60.3
pctWWage                 59.6
numbUrban                58.2
MedOwnCostPctIncNoMtg    56.8
pctUrban                 56.6
NumStreet                54.3
PctEmploy                53.4
NumImmig                 52.7</code></pre>
<pre class="r"><code>varimp_glm_clean</code></pre>
<pre><code>glm variable importance

  only 20 most important variables shown (out of 60)

                      Overall
LandArea                100.0
MalePctNevMarr           58.8
PctVacantBoarded         58.0
HispPerCap               56.5
NumStreet                55.4
blackPerCap              52.2
MedNumBR                 50.2
PctVacMore6Mos           48.7
agePct16t24              47.6
AsianPerCap              45.8
OwnOccQrange             43.5
LemasPctOfficDrugUn      43.0
racePctWhite             42.6
indianPerCap             40.3
PctUnemployed            36.6
MedOwnCostPctIncNoMtg    34.6
PctYoungKids2Par         33.8
whitePerCap              32.4
FemalePctDiv             30.6
PctKidsBornNeverMar      30.5</code></pre>
<pre class="r"><code>varimp_glm_pca</code></pre>
<pre><code>glm variable importance

     Overall
PC1  100.000
PC2   62.415
PC3   58.250
PC5   46.031
PC4   45.273
PC7   39.760
PC8   30.465
PC10   5.043
PC11   3.375
PC6    0.752
PC9    0.000</code></pre>
<pre class="r"><code># print variable importance
plot(varimp_glm)</code></pre>
<p><img src="Features_practical_files/figure-html/unnamed-chunk-35-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(varimp_glm_clean)</code></pre>
<p><img src="Features_practical_files/figure-html/unnamed-chunk-35-2.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(varimp_glm_pca)</code></pre>
<p><img src="Features_practical_files/figure-html/unnamed-chunk-35-3.png" width="576" style="display: block; margin: auto;" /></p>
<ol start="14" style="list-style-type: decimal">
<li>Now that you know which features were most important, do you think you can come up with a set of features that reliably outperforms thew predictions based on the pca-generated feature set? Try it out!</li>
</ol>
</div>
</div>
<div id="z---violent-non-violent-crime-data" class="section level3">
<h3>Z - Violent &amp; Non-violent Crime Data</h3>
<ol style="list-style-type: decimal">
<li><p>Analyze the violent and non-violent crime data sets predicting either the number of violent crimes per 100k inhabitants (<code>ViolentCrimesPerPop</code>) or the number of non-violent crimes per 100k inhabitants (<code>nonViolPerPop</code>). Both criteria are numeric, implying that this is not classification problem, but one of regression. Other than that, the features in the data set are identical to the previous analyses. How well can you predict violent or non-violent crimes?</p></li>
<li><p>Another approach to feature selection, beyond selection by hand or PCA, is to have the computer try to automically select subsets of features that lead to the best possible cross-validation performance. One such process is called recursive feature elimination. Try it out using <code>caret</code>’s <code>rfe()</code> function. See code below.</p></li>
</ol>
<pre class="r"><code># split index
train_index &lt;- createDataPartition(violent_crime$ViolentCrimesPerPop, 
                                   p = .8, 
                                   list = FALSE)

# train and test sets
violent_train &lt;- violent_crime %&gt;% slice(train_index)
violent_test  &lt;- violent_crime %&gt;% slice(-train_index)

# remove extreme correlations (OPTIONAL)
predictors &lt;- violent_train %&gt;% select(-ViolentCrimesPerPop)
predictors &lt;- predictors %&gt;% select(-findCorrelation(cor(predictors)))
violent_train_clean &lt;- predictors %&gt;%
  add_column(ViolentCrimesPerPop = violent_train$ViolentCrimesPerPop)

# Feature elimination settings 
ctrl_rfe &lt;- rfeControl(functions = lmFuncs,  # linear model
                          method = &quot;cv&quot;,
                          verbose = FALSE,
                          rerank = FALSE)

# Run feature elimination
profile &lt;- rfe(x = violent_train %&gt;% select(-ViolentCrimesPerPop), 
               y = violent_train$ViolentCrimesPerPop,
               sizes = 1:(ncol(violent_train_clean)-1), # Features set sizes
               rfeControl = ctrl_rfe)

# inspect cross-validation as a function of performance
plot(profile)</code></pre>
</div>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<pre class="r"><code># Step 0: Load packages-----------

library(tidyverse)    # Load tidyverse for dplyr and tidyr
library(tibble)       # For advanced tibble functions
library(caret)        # For ML mastery 

# Step 1: Load, prepare, and explore data ----------------------

# read data
data &lt;- read_csv(&quot;1_Data/mpg_num.csv&quot;)

# Convert all characters to factors
data &lt;- data %&gt;%
  mutate_if(is.character, factor)

# Explore training data
data        # Print the dataset
dim(data)   # Print dimensions
names(data) # Print the names

# Step 2: Create training and test sets -------------

# Create train index
train_index &lt;- createDataPartition(criterion, 
                                   p = .8, 
                                   list = FALSE)

# Create training and test sets
data_train &lt;- data %&gt;% slice(train_index)
data_test &lt;- data %&gt;% slice(-train_index)

# split predictors and criterion
criterion_train &lt;- data_train %&gt;% select(hwy) %&gt;% pull()
predictors_train &lt;- data_train %&gt;% select(-hwy)
criterion_test &lt;- data_test %&gt;% select(hwy) %&gt;% pull()
predictors_test &lt;- data_test %&gt;% select(-hwy)

# Step 3: Clean data -------------

# Test for excessively correlated features
corr_matrix &lt;- cor(predictors_train)
corr_features &lt;- findCorrelation(corr_matrix)

# Remove excessively correlated features
predictors_train &lt;- predictors_train %&gt;% select(-corr_features)

# Test for near zero variance features
zerovar_features &lt;- nearZeroVar(predictors_train)

# Remove near zero variance features
predictors_train &lt;- predictors_train %&gt;% select(-zerovar_features)

# recombine data
data_train &lt;- predictors_train %&gt;% add_column(hwy = criterion_train)

# Step 4: Define training control parameters -------------

# Train using cross-validation
ctrl_cv &lt;- trainControl(method = &quot;cv&quot;) 

# Step 5: Fit models -------------

# Fit glm vanilla flavor
hwy_glm &lt;- train(form = hwy ~ .,
                 data = data_train,
                 method = &quot;glm&quot;,
                 trControl = ctrl_cv)

# Fit with pca transformation
hwy_glm_pca &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv,
                     preProcess = c(&#39;pca&#39;))

# Fit scaling and centering
hwy_glm_sca &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv,
                     preProcess = c(&#39;scale&#39;, &#39;center&#39;))

# Get fits
glm_fit     &lt;- predict(hwy_glm)
glm_pca_fit &lt;- predict(hwy_glm_pca)
glm_sca_fit &lt;- predict(hwy_glm_sca)

# Step 6: Evaluate variable importance -------------

# Run varImp()
imp_glm     &lt;- varImp(hwy_glm)
imp_glm_pca &lt;- varImp(hwy_glm_pca)
imp_glm_sca &lt;- varImp(hwy_glm_sca)

# Plot variable importance
plot(imp_glm)
plot(imp_glm_pca)
plot(imp_glm_sca)

# Step 7: Select variables -------------

# Select by hand in formula
hwy_glm_sel &lt;- train(form = hwy ~ cty,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv)

# Select by reducing pca criterion ---

# Reduce criterion to 50% variance epxlained 
ctrl_cv_pca &lt;- trainControl(method = &quot;cv&quot;,
                            preProcOptions = list(thresh = 0.50)) 

# Refit model with update
hwy_glm_sel &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv_pca,
                     preProcess = c(&#39;pca&#39;))

# Step 8: Recursive feature elimination -------------

# Feature elimination settings 
ctrl_rfe &lt;- rfeControl(functions = lmFuncs,  # linear model
                       method = &quot;cv&quot;,
                       verbose = FALSE)

# Run feature elimination
profile &lt;- rfe(x = predictors_train, 
               y = criterion_train,
               sizes = c(1, 2, 3),     # Features set sizes should be considered
               rfeControl = ctrl_rfe)

# plot result
trellis.par.set(caretTheme())
plot(profile, type = c(&quot;g&quot;, &quot;o&quot;))

# Step 9: Evaluate models -------------

# you know how...</code></pre>
</div>
<div id="datasets" class="section level2">
<h2>Datasets</h2>
<table>
<thead>
<tr class="header">
<th align="left">File</th>
<th align="left">Rows</th>
<th align="left">Columns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/pima_diabetes.csv">pima_diabetes</a></td>
<td align="left">724</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/murders_crime.csv">murders_crime</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/violent_crime.csv">violent_crime</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/nonviolent_crime.csv">nonviolent_crime</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
</tbody>
</table>
<ul>
<li><p>The <code>pima_diabetes</code> is a subset of the <code>PimaIndiansDiabetes2</code> data set in the <code>mlbench</code> package. It contains medical and demographic data of Pima Indians.</p></li>
<li><p>The <code>murders_crime</code>, <code>violent_crime</code>, and <code>non_violent_crime</code> data are subsets of the Communities and Crime Unnormalized Data Set data set from the UCI Machine Learning Repository. To see column descriptions, visit this site: <a href="https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized">Communities and Crime Unnormalized Data Set</a>. Due to the large number of variables (102), we do not include the full tables below.</p></li>
</ul>
<div id="variable-description-of-pima_diabetes" class="section level4">
<h4>Variable description of <code>pima_diabetes</code></h4>
<table>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>pregnant</code></td>
<td align="left">Number of times pregnant.</td>
</tr>
<tr class="even">
<td align="left"><code>glucose</code></td>
<td align="left">Plasma glucose concentration (glucose tolerance test).</td>
</tr>
<tr class="odd">
<td align="left"><code>pressure</code></td>
<td align="left">Diastolic blood pressure (mm Hg).</td>
</tr>
<tr class="even">
<td align="left"><code>triceps</code></td>
<td align="left">Triceps skin fold thickness (mm).</td>
</tr>
<tr class="odd">
<td align="left"><code>insulin</code></td>
<td align="left">2-Hour serum insulin (mu U/ml).</td>
</tr>
<tr class="even">
<td align="left"><code>mass</code></td>
<td align="left">Body mass index (weight in kg/(height in m)^2).</td>
</tr>
<tr class="odd">
<td align="left"><code>pedigree</code></td>
<td align="left">Diabetes pedigree function.</td>
</tr>
<tr class="even">
<td align="left"><code>age</code></td>
<td align="left">Age (years).</td>
</tr>
<tr class="odd">
<td align="left"><code>diabetes</code></td>
<td align="left">Class variable (test for diabetes).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="functions" class="section level2">
<h2>Functions</h2>
<div id="packages" class="section level3">
<h3>Packages</h3>
<table>
<thead>
<tr class="header">
<th align="left">Package</th>
<th align="left">Installation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>tidyverse</code></td>
<td align="left"><code>install.packages("tidyverse")</code></td>
</tr>
<tr class="even">
<td align="left"><code>tibble</code></td>
<td align="left"><code>install.packages("tibble")</code></td>
</tr>
<tr class="odd">
<td align="left"><code>caret</code></td>
<td align="left"><code>install.packages("caret")</code></td>
</tr>
</tbody>
</table>
</div>
<div id="functions-1" class="section level3">
<h3>Functions</h3>
<table>
<colgroup>
<col width="7%" />
<col width="12%" />
<col width="80%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="left">Package</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>trainControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Define modelling control parameters</td>
</tr>
<tr class="even">
<td align="left"><code>train()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Train a model</td>
</tr>
<tr class="odd">
<td align="left"><code>predict(object, newdata)</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Predict the criterion values of <code>newdata</code> based on <code>object</code></td>
</tr>
<tr class="even">
<td align="left"><code>postResample()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in regression tasks</td>
</tr>
<tr class="odd">
<td align="left"><code>confusionMatrix()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in classification tasks</td>
</tr>
<tr class="even">
<td align="left"><code>varImp()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Determine the model-specific importance of features</td>
</tr>
<tr class="odd">
<td align="left"><code>findCorrelation()</code>, <code>nearZeroVar()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Identify highly correlated and low variance features.</td>
</tr>
<tr class="even">
<td align="left"><code>rfe()</code>, <code>rfeControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Run and control recursive feature selection.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="resources" class="section level2">
<h2>Resources</h2>
<div id="cheatsheet" class="section level3">
<h3>Cheatsheet</h3>
<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf"> <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%"></a><br> <font style="font-size:10px"> from <a href= "https://github.com/rstudio/cheatsheets/raw/master/caret.pdf</figcaption">github.com/rstudio</a></font>
</figure>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
