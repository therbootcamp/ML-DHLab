<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Optimization</title>

<script src="Optimization_practical_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Optimization_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Optimization_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Optimization_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Optimization_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Optimization_practical_files/navigation-1.1/tabsets.js"></script>
<link href="Optimization_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Optimization_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="practical.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Optimization</h1>
<h4 class="author"><table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'>
<col width='10%'>
<col width='10%'>
<tr style="border:none">
<td style="display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none" nowrap>
<font style='font-style:normal'>Machine Learning with R</font><br> <a href='https://therbootcamp.github.io/ML-DHLab/'> <i class='fas fa-clock' style='font-size:.9em;' ></i> </a> <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;'></i> </a> <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a> <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a> <a href='https://therbootcamp.github.io'> <font style='font-style:normal'>The R Bootcamp</font> </a>
</td>
<td style="width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none">
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
</td>
</tr>
</table></h4>

</div>


<p align="center">
<img width="100%" src="image/rexthor.png" margin=0><br> <font style="font-size:10px">from <a href="https://xkcd.com/1725/">xkcd.com</a></font>
</p>
<div id="section" class="section level1 tabset">
<h1></h1>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>By the end of this practical you will know how to:</p>
<ol style="list-style-type: decimal">
<li>Use cross-validation to select optimal model tuning parameters for decision trees and random forests.</li>
<li>Compare ‘standard’ regression with lasso and ridge penalised regression.</li>
</ol>
</div>
<div id="tasks" class="section level2">
<h2>Tasks</h2>
<div id="a---setup" class="section level3">
<h3>A - Setup</h3>
<ol style="list-style-type: decimal">
<li><p>Open your <code>TheRBootcamp</code> R project.</p></li>
<li><p>Open a new R script. At the top of the script, using comments, write your name and the date.</p></li>
</ol>
<pre class="r"><code>## NAME
## DATE
## Optimizing practical</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Save the script as a new file called <code>Optimization_practical.R</code> in the <code>2_Code</code> folder.</p></li>
<li><p>Using <code>library()</code> load the packages <code>tidyverse</code>, <code>caret</code>, <code>party</code>, <code>partykit</code>.</p></li>
</ol>
</div>
<div id="b---load-the-graduation-data" class="section level3">
<h3>B - Load the <code>graduation</code> data</h3>
<ol style="list-style-type: decimal">
<li>You will again begin by analyzing the graduation data. Read in the data sets <code>graduation_train.csv</code> and <code>graduation_test.csv</code> and convert all character to factors.</li>
</ol>
<pre class="r"><code># Read college data
college_train &lt;- read_csv(file = &quot;1_Data/college_train.csv&quot;)
college_test &lt;- read_csv(file = &quot;1_Data/college_test.csv&quot;)

# Convert all character features to factor
college_train &lt;- college_train %&gt;%
  mutate_if(is.character, factor) 
college_test &lt;- college_test %&gt;%
          mutate_if(is.character, factor)</code></pre>
</div>
<div id="c---setup-traincontrol" class="section level3">
<h3>C - Setup <code>trainControl</code></h3>
<ol style="list-style-type: decimal">
<li>Now, you finally make use of the train control object by specifying 10-fold cross-validation as the preferred optimization method in an object called <code>ctrl_cv</code>. Specifically:</li>
</ol>
<ul>
<li>set <code>method = "cv"</code> to specify cross validation.</li>
<li>set <code>number = 10</code> to specify 10 folds.</li>
</ul>
<pre class="r"><code># Use 10-fold cross validation
ctrl_cv &lt;- trainControl(method = &quot;XX&quot;, 
                        number = XX) </code></pre>
</div>
<div id="d---regularized-regression" class="section level3">
<h3>D - Regularized regression</h3>
<div id="standard-regression" class="section level4">
<h4>Standard regression</h4>
<ol style="list-style-type: decimal">
<li>Begin by fitting a standard regression model predicting <code>Grad.Rate</code> as a function of all other features. Specifically:</li>
</ol>
<ul>
<li>set the formula to <code>Grad.Rate ~ .</code>.</li>
<li>set the data to <code>college_train</code>.</li>
<li>set the method to <code>"glm"</code> for standard regression.</li>
<li>set the train control argument to <code>ctrl_cv</code>.</li>
</ul>
<pre class="r"><code># Standard regression 
graduation_glm &lt;- train(form = XX ~ .,
                        data = XX,
                        method = &quot;XX&quot;,
                        trControl = XX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>What were your final regression model coefficients?</li>
</ol>
<pre class="r"><code># Show final model
graduation_glm$finalModel</code></pre>
</div>
<div id="ridge-regression" class="section level4">
<h4>Ridge regression</h4>
<ol start="3" style="list-style-type: decimal">
<li>Before you can fit a regularized regression model like ridge regression, you need to determine a vector of lambda penalty values that the cross validation procedure will evaluate. Using the code below, create a vector called <code>lambda_vec</code> containing 100 values spanning a range from very close to <code>0</code> up to <code>100</code>.</li>
</ol>
<pre class="r"><code># Vector of lambda values to try
lambda_vec &lt;- 10 ^ (seq(-3, 2, length = 100))</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Using <code>train()</code>, fit a ridge regression model predicting <code>Grad.Rate</code> as a function of all features. This time make use of the <code>tuneGrid</code>, which will take a <code>data.frame</code> specifying the sets of tuning parameters to consider during cross validation. In addition to <code>alpha = 0</code>, which specifies a ridge penalty, add <code>lambda = lambda_vec</code>. Also, don’t forget to <code>"center"</code> and <code>"scale"</code> when using regularization.</li>
</ol>
<pre class="r"><code># Ridge regression 
graduation_ridge &lt;- train(form = XX ~ .,
                          data = XX,
                          method = &quot;XX&quot;,
                          trControl = XX,
                          preProcess = c(&quot;XX&quot;, &quot;XX&quot;),          # Standardize
                          tuneGrid = data.frame(alpha = 0,     # Ridge penalty
                                                lambda = XX))  # Penalty weight</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>Print your <code>graduation_ridge</code> object. Which lambda was selected as best performing?</p></li>
<li><p>Plot your <code>graduation_ridge</code> object. What do you see? Does this match the plot match the value identified in the previous task?</p></li>
</ol>
<pre class="r"><code># Plot graduation_ridge object
plot(XX)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>What were your final regression model coefficients for the best lambda value? Find them by running the following code.</li>
</ol>
<pre class="r"><code># Get coefficients from best lambda value
coef(graduation_ridge$finalModel, 
     graduation_ridge$bestTune$lambda)</code></pre>
<ol start="8" style="list-style-type: decimal">
<li><p>How do these coefficients compare to what you found in regular regression? Are they similar? Could the differences have something to do with the applied scaling?</p></li>
<li><p>Using <code>predict()</code> save the fitted values of <code>graduation_glm</code> object as <code>glm_fit</code>.</p></li>
</ol>
</div>
<div id="lasso-regression" class="section level4">
<h4>Lasso regression</h4>
<ol start="10" style="list-style-type: decimal">
<li>Now fit a lasso regression model predicting <code>Grad.Rate</code> as a function of all features. Set <code>alpha = 1</code> for the Lasso penalty and add <code>lambda = lambda_vec</code> as above.</li>
</ol>
<pre class="r"><code># Lasso regression 
graduation_lasso &lt;- train(form = XX ~ .,
                          data = XX,
                          method = &quot;XX&quot;,
                          trControl = XX,
                          preProcess = c(&quot;XX&quot;, &quot;XX&quot;),         # Standardise
                          tuneGrid = data.frame(alpha = XX,   # Lasso penalty
                                                lambda = XX)) # Penalty weight</code></pre>
<ol start="11" style="list-style-type: decimal">
<li><p>Print your <code>graduation_lasso</code> object. Which lambda was selected as best performing?</p></li>
<li><p>Plot your <code>graduation_lasso</code> object. What do you see? Does this match the plot match the value identified in the previous task?</p></li>
</ol>
<pre class="r"><code># Plot model object
plot(XX)</code></pre>
<ol start="13" style="list-style-type: decimal">
<li>What were your final regression model coefficients for the best lambda value? Find them by running the following code.</li>
</ol>
<pre class="r"><code># Get coefficients from best lambda value
coef(graduation_lasso$finalModel, 
     graduation_lasso$bestTune$lambda)</code></pre>
<ol start="14" style="list-style-type: decimal">
<li>How do these coefficients compare to what you found for the regular and ridge regression? Have some features been set to 0?</li>
</ol>
</div>
<div id="evaluate-performance" class="section level4">
<h4>Evaluate performance</h4>
<ol start="15" style="list-style-type: decimal">
<li>Store the training data and test data criterion (<code>Grad.Rate</code>) as <code>criterion_train</code> and <code>criterion_test</code>.</li>
</ol>
<p>s 16. Using <code>predict()</code>, save the fitted values of your models as <code>glm_fit</code>, <code>ridge_fit</code>, and <code>lasso_fit</code>.</p>
<ol start="17" style="list-style-type: decimal">
<li><p>Using <code>postResample</code> evaluate the fitting performance of your models. Which model has the best performance in fitting the training data?</p></li>
<li><p>Using <code>predict()</code> and <code>newdata = college_test</code>, save the predicted values of your models as <code>glm_pred</code>, <code>ridge_pred</code>, and <code>lasso_pred</code>.</p></li>
<li><p>Using <code>postResample</code> evaluate the prediction performance of your models. Which model has the best performance in predicting the test data? Did the regularized regressions outperform the unregularized one?</p></li>
</ol>
</div>
</div>
<div id="e---trees" class="section level3">
<h3>E - Trees</h3>
<div id="decision-tree" class="section level4">
<h4>Decision tree</h4>
<ol style="list-style-type: decimal">
<li><p>It’s time to see what parameter tuning can do for decision trees and random forests. To do this, first, determine a vector of possible values for the complexity parameter <code>cp</code> of decision trees. To this end, using the code below, create a vector called <code>cp_vec</code> which contains 100 values between 0 and .2.</p></li>
<li><p>Using <code>train()</code>, fit a decision tree model called <code>graduation_rpart</code> predicting <code>Grad.Rate</code>by all features. Again, assign a data frame to <code>tuneGrid</code> specifying the possible tuning parameters, i.e., <code>cp = cp_vec</code>.</p></li>
</ol>
<pre class="r"><code># Decision tree
graduation_rpart &lt;- train(form = Grad.part ~ .,
                          data = XX,
                          method = &quot;XX&quot;,
                          trControl = XX,
                          tuneGrid = data.frame(cp = XX))</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Print your <code>graduation_rpart</code> object. Which <code>cp</code> was selected as best performing?</p></li>
<li><p>Plot your <code>graduation_rpart</code> object. What do you see? Does this match the plot match the value identified in the previous task?</p></li>
<li><p>Plot your final decision tree using the following code. Do you find the model sensible?</p></li>
</ol>
<pre class="r"><code># Visualise your trees
plot(as.party(graduation_rpart$finalModel)) </code></pre>
<ol start="6" style="list-style-type: decimal">
<li>How do the nodes in the tree compare to those in the ridge or lasso models?</li>
</ol>
</div>
<div id="random-forest" class="section level4">
<h4>Random forest</h4>
<ol start="7" style="list-style-type: decimal">
<li><p>Now onto fitting a random forest. Using the code below, create a vector called <code>mtry_vec</code> containing values from 1 to 5, the tuning parameter candidates for our random forest.</p></li>
<li><p>Fit a random forest model predicting <code>Grad.Rate</code> as a function of all features. Make sure to use <code>mtry = mtry_vec</code> within the data frame specifying the <code>tuneGrid</code>. This one might take a bit longer than usual.</p></li>
</ol>
<pre class="r"><code># Random forest
graduation_rf &lt;- train(form = XX ~ .,
                   data = XX,
                   method = &quot;XX&quot;,
                   trControl = XX,
                   tuneGrid = data.frame(mtry = XX))</code></pre>
<ol start="9" style="list-style-type: decimal">
<li><p>Print your <code>graduation_rf</code> object. What do you see? Which <code>mtry</code> was selected as best performing?</p></li>
<li><p>Plot your <code>graduation_rf</code> object. What do you see? Does this match the plot match the value identified in the previous task?</p></li>
</ol>
</div>
<div id="evaluate-performance-1" class="section level4">
<h4>Evaluate performance</h4>
<ol start="11" style="list-style-type: decimal">
<li><p>Using <code>predict()</code>, save the fitted values of your tree models as <code>rpart_fit</code> and <code>rf_fit</code>.</p></li>
<li><p>Using <code>postResample</code> evaluate the fitting performance of your models. Which model has the best performance in fitting the training data? If you like compare to the regression models of the previous section.</p></li>
<li><p>Using <code>predict()</code> and <code>newdata = college_test</code>, save the predicted values of your models as <code>rpart_pred</code>, and <code>rf_pred</code>.</p></li>
<li><p>Using <code>postResample</code> evaluate the prediction performance of your models. Which model has the best performance in predicting the test data? Did the tree models outperform the regularized regressions?</p></li>
</ol>
</div>
</div>
<div id="x---challenges-explore-tuning-parameter-grids" class="section level3">
<h3>X - Challenges: Explore tuning parameter grids</h3>
<ol style="list-style-type: decimal">
<li>The name <code>tuneGrid</code> already suggests that one may want to vary multiple tuning parameters at the same time. A handy function helping in this is <code>expand.grid()</code>, which will produce all compbinations of values of the vectors supplied as its arguments. Try, e.g., <code>expand.grid(a = c(1, 2), b = c(2, 3, 4))</code>. The template below shows you how you can use <code>expand.grid()</code> to specify multiple tuning parameters at the same time.</li>
</ol>
<pre class="r"><code>model &lt;- train(form = XX ~ .,
               data = XX,
               method = &quot;XX&quot;,
               trControl = XX,
               preProcess = c(&quot;XX&quot;, &quot;XX&quot;),         
               tuneGrid = expand.grid(parameter_1 = XX,    
                                      parameter_2 = XX)) </code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Run and evaluate a regularized regression that uses cross validation to not only identify the best value for <code>lambda</code> but also the best value for <code>alpha</code>, e.g., using <code>alpha = c(0, .5, 1)</code>. This way you can let the procedure decide whether to use ridge, lasso or both.</p></li>
<li><p>Run and evaluate a random forest while tuning not only <code>mtry</code> but also <code>ntree</code>, e.g., using <code>ntree = c(100,500,1000)</code>. Tip: avoid high values for <code>ntree</code> or <code>mtry</code>.</p></li>
<li><p>As done in the previous sessions try predicting <code>Private</code> rather than <code>Grad.Rate</code>. Note, this may require a different range of lambda values. You’ll figure it out.</p></li>
</ol>
</div>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<pre class="r"><code># Model optimization with Regression

# Step 0: Load packages-----------
library(tidyverse)    # Load tidyverse for dplyr and tidyr
library(caret)        # For ML mastery 
library(partykit)     # For decision trees
library(party)        # For decision trees

# Step 1: Load, clean, and explore data ----------------------

# training data
data_train &lt;- read_csv(&quot;1_Data/diamonds_train.csv&quot;)

# test data
data_test &lt;- read_csv(&quot;1_Data/diamonds_test.csv&quot;)

# Convert all characters to factor
#  Some ML models require factors
data_train &lt;- data_train %&gt;%
  mutate_if(is.character, factor)

data_test &lt;- data_test %&gt;%
  mutate_if(is.character, factor)

# Explore training data
data_train        # Print the dataset
View(data_train)  # Open in a new spreadsheet-like window 
dim(data_train)   # Print dimensions
names(data_train) # Print the names

# Define criterion_train
criterion_train &lt;- data_train$price
criterion_test &lt;- data_test$price

# Step 2: Define training control parameters -------------

# Use 10-fold cross validation
ctrl_cv &lt;- trainControl(method = &quot;cv&quot;, 
                        number = 10) 

# Step 3: Train models: -----------------------------

# Normal Regression --------------------------
price_glm &lt;- train(form = price ~ carat + depth + table + x + y,
                   data = data_train,
                   method = &quot;glm&quot;,
                   trControl = ctrl_cv)


# Print key results
price_glm

# Coefficients
coef(price_glm$finalModel)

# Lasso --------------------------

# Vector of lambda values to try
lambda_vec &lt;- 10 ^ seq(-3, 3, length = 100)

price_lasso &lt;- train(form = price ~ carat + depth + table + x + y,
                   data = data_train,
                   method = &quot;glmnet&quot;,
                   trControl = ctrl_cv,
                   preProcess = c(&quot;center&quot;, &quot;scale&quot;),  # Standardise
                   tuneGrid = data.frame(alpha = 1,  # Lasso
                                          lambda = lambda_vec))


# Print key results
price_lasso

# Plot regularisation parameter versus error
plot(price_lasso)

# Print best regularisation parameter
price_lasso$bestTune$lambda

# Get coefficients from best lambda value
coef(price_lasso$finalModel, 
     price_lasso$bestTune$lambda)

# Ridge --------------------------

# Vector of lambda values to try
lambda_vec &lt;- 10 ^ seq(-3, 3, length = 100)

price_ridge &lt;- train(form = price ~ carat + depth + table + x + y,
                     data = data_train,
                     method = &quot;glmnet&quot;,
                     trControl = ctrl_cv,
                     preProcess = c(&quot;center&quot;, &quot;scale&quot;),  # Standardise
                     tuneGrid = data.frame(alpha = 0,     # Ridge penalty
                                            lambda = lambda_vec))

# Print key results
price_ridge

# Plot regularisation parameter versus error
plot(price_ridge)

# Print best regularisation parameter
price_ridge$bestTune$lambda

# Get coefficients from best lambda value
coef(price_ridge$finalModel, 
     price_ridge$bestTune$lambda)


# Decision Trees --------------------------

# Vector of cp values to try
cp_vec &lt;- seq(0, .1, length = 100)

price_rpart &lt;- train(form = price ~ carat + depth + table + x + y,
                  data = data_train,
                  method = &quot;rpart&quot;,
                  trControl = ctrl_cv,
                  tuneGrid = data.frame(cp = cp_vec))

# Print key results
price_rpart

# Plot complexity parameter vs. error
plot(price_rpart)

# Print best complexity parameter
price_rpart$bestTune$cp</code></pre>
</div>
<div id="datasets" class="section level2">
<h2>Datasets</h2>
<table>
<thead>
<tr class="header">
<th align="left">File</th>
<th align="left">Rows</th>
<th align="left">Columns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_train.csv">college_train.csv</a></td>
<td align="left">50</td>
<td align="left">20</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_test.csv">college_test.csv</a></td>
<td align="left">213</td>
<td align="left">20</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_train.csv">college_train.csv</a></td>
<td align="left">500</td>
<td align="left">18</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_test.csv">college_test.csv</a></td>
<td align="left">277</td>
<td align="left">18</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/house_train.csv">house_train.csv</a></td>
<td align="left">5000</td>
<td align="left">21</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2019Oct/master/1_Data/college_test.csv">house_test.csv</a></td>
<td align="left">1000</td>
<td align="left">21</td>
</tr>
</tbody>
</table>
<ul>
<li><p>The <code>college_train</code> and <code>college_test</code> data are taken from the <code>College</code> dataset in the <code>ISLR</code> package. They contain statistics for a large number of US Colleges from the 1995 issue of US News and World Report.</p></li>
<li><p>The <code>house_train</code> and <code>house_test</code> data come from <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">https://www.kaggle.com/harlfoxem/housesalesprediction</a></p></li>
</ul>
<div id="variable-description-of-college_train-and-college_test" class="section level4">
<h4>Variable description of <code>college_train</code> and <code>college_test</code></h4>
<table>
<colgroup>
<col width="26%" />
<col width="73%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>Private</code></td>
<td align="left">A factor with levels No and Yes indicating private or public university.</td>
</tr>
<tr class="even">
<td align="left"><code>Apps</code></td>
<td align="left">Number of applications received.</td>
</tr>
<tr class="odd">
<td align="left"><code>Accept</code></td>
<td align="left">Number of applications accepted.</td>
</tr>
<tr class="even">
<td align="left"><code>Enroll</code></td>
<td align="left">Number of new students enrolled.</td>
</tr>
<tr class="odd">
<td align="left"><code>Top10perc</code></td>
<td align="left">Pct. new students from top 10% of H.S. class.</td>
</tr>
<tr class="even">
<td align="left"><code>Top25perc</code></td>
<td align="left">Pct. new students from top 25% of H.S. class.</td>
</tr>
<tr class="odd">
<td align="left"><code>F.Undergrad</code></td>
<td align="left">Number of fulltime undergraduates.</td>
</tr>
<tr class="even">
<td align="left"><code>P.Undergrad</code></td>
<td align="left">Number of parttime undergraduates.</td>
</tr>
<tr class="odd">
<td align="left"><code>Outstate</code></td>
<td align="left">Out-of-state tuition.</td>
</tr>
<tr class="even">
<td align="left"><code>Room.Board</code></td>
<td align="left">Room and board costs.</td>
</tr>
<tr class="odd">
<td align="left"><code>Books</code></td>
<td align="left">Estimated book costs.</td>
</tr>
<tr class="even">
<td align="left"><code>Personal</code></td>
<td align="left">Estimated personal spending.</td>
</tr>
<tr class="odd">
<td align="left"><code>PhD</code></td>
<td align="left">Pct. of faculty with Ph.D.’s.</td>
</tr>
<tr class="even">
<td align="left"><code>Terminal</code></td>
<td align="left">Pct. of faculty with terminal degree.</td>
</tr>
<tr class="odd">
<td align="left"><code>S.F.Ratio</code></td>
<td align="left">Student/faculty ratio.</td>
</tr>
<tr class="even">
<td align="left"><code>perc.alumni</code></td>
<td align="left">Pct. alumni who donate.</td>
</tr>
<tr class="odd">
<td align="left"><code>Expend</code></td>
<td align="left">Instructional expenditure per student.</td>
</tr>
<tr class="even">
<td align="left"><code>Grad.Rate</code></td>
<td align="left">Graduation rate.</td>
</tr>
</tbody>
</table>
</div>
<div id="variable-description-of-house_train-and-house_test" class="section level4">
<h4>Variable description of <code>house_train</code> and <code>house_test</code></h4>
<table>
<colgroup>
<col width="26%" />
<col width="73%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>price</code></td>
<td align="left">Price of the house in $.</td>
</tr>
<tr class="even">
<td align="left"><code>bedrooms</code></td>
<td align="left">Number of bedrooms.</td>
</tr>
<tr class="odd">
<td align="left"><code>bathrooms</code></td>
<td align="left">Number of bathrooms.</td>
</tr>
<tr class="even">
<td align="left"><code>sqft_living</code></td>
<td align="left">Square footage of the home.</td>
</tr>
<tr class="odd">
<td align="left"><code>sqft_lot</code></td>
<td align="left">Square footage of the lot.</td>
</tr>
<tr class="even">
<td align="left"><code>floors</code></td>
<td align="left">Total floors (levels) in house.</td>
</tr>
<tr class="odd">
<td align="left"><code>waterfront</code></td>
<td align="left">House which has a view to a waterfront.</td>
</tr>
<tr class="even">
<td align="left"><code>view</code></td>
<td align="left">Has been viewed.</td>
</tr>
<tr class="odd">
<td align="left"><code>condition</code></td>
<td align="left">How good the condition is (Overall).</td>
</tr>
<tr class="even">
<td align="left"><code>grade</code></td>
<td align="left">Overall grade given to the housing unit, based on King County grading system.</td>
</tr>
<tr class="odd">
<td align="left"><code>sqft_above</code></td>
<td align="left">Square footage of house apart from basement.</td>
</tr>
<tr class="even">
<td align="left"><code>sqft_basement</code></td>
<td align="left">Square footage of the basement.</td>
</tr>
<tr class="odd">
<td align="left"><code>yr_built</code></td>
<td align="left">Built Year.</td>
</tr>
<tr class="even">
<td align="left"><code>yr_renovated</code></td>
<td align="left">Year when house was renovated.</td>
</tr>
<tr class="odd">
<td align="left"><code>zipcode</code></td>
<td align="left">Zip code.</td>
</tr>
<tr class="even">
<td align="left"><code>lat</code></td>
<td align="left">Latitude coordinate.</td>
</tr>
<tr class="odd">
<td align="left"><code>long</code></td>
<td align="left">Longitude coordinate.</td>
</tr>
<tr class="even">
<td align="left"><code>sqft_living15</code></td>
<td align="left">Living room area in 2015 (implies some renovations). This might or might not have affected the lotsize area.</td>
</tr>
<tr class="odd">
<td align="left"><code>sqft_lot15</code></td>
<td align="left">lot-size area in 2015 (implies some renovations).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="functions" class="section level2">
<h2>Functions</h2>
<div id="packages" class="section level3">
<h3>Packages</h3>
<table>
<thead>
<tr class="header">
<th align="left">Package</th>
<th align="left">Installation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>tidyverse</code></td>
<td align="left"><code>install.packages("tidyverse")</code></td>
</tr>
<tr class="even">
<td align="left"><code>caret</code></td>
<td align="left"><code>install.packages("caret")</code></td>
</tr>
<tr class="odd">
<td align="left"><code>partykit</code></td>
<td align="left"><code>install.packages("partykit")</code></td>
</tr>
<tr class="even">
<td align="left"><code>party</code></td>
<td align="left"><code>install.packages("party")</code></td>
</tr>
</tbody>
</table>
</div>
<div id="functions-1" class="section level3">
<h3>Functions</h3>
<table>
<colgroup>
<col width="7%" />
<col width="12%" />
<col width="80%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="left">Package</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>trainControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Define modelling control parameters</td>
</tr>
<tr class="even">
<td align="left"><code>train()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Train a model</td>
</tr>
<tr class="odd">
<td align="left"><code>predict(object, newdata)</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Predict the criterion values of <code>newdata</code> based on <code>object</code></td>
</tr>
<tr class="even">
<td align="left"><code>postResample()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in regression tasks</td>
</tr>
<tr class="odd">
<td align="left"><code>confusionMatrix()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Calculate aggregate model performance in classification tasks</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="resources" class="section level2">
<h2>Resources</h2>
<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf"> <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%"></a><br> <font style="font-size:10px"> from <a href= "https://github.com/rstudio/cheatsheets/raw/master/caret.pdf</figcaption">github.com/rstudio</a></font>
</figure>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
